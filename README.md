# Protecto_Final_Data - An√°lisis de Datos

## Primera Sesion
### Descripci√≥n del Proyecto
Este es un proyecto final donde se trabajar√° en la transformaci√≥n, limpieza y an√°lisis de datos. Mi enfoque es hacer una **ETL** (extracci√≥n, transformaci√≥n y carga) utilizando **Python** para la limpieza y transformaci√≥n de los datos, y luego realizar el an√°lisis y la visualizaci√≥n utilizando **Power BI**.

#### Nota de la conversaci√≥n con Silvia
Una vez hablado con Silvia, mi intenci√≥n es hacer una ETL en Python y utilizar Power BI para el an√°lisis y la visualizaci√≥n. He recibido su aprobaci√≥n para esta estrategia, siempre y cuando utilice Python para la limpieza y transformaci√≥n de los datos. 
Le he explicado que tengo 7 bases de datos diferentes y que mi objetivo es pasar de un modelo en copo de nieve a un modelo estrella en Power BI y asi poder usar la herramienta en la que me estoy especializando al maximo, sin olvidar el resto.

## Objetivos
### **Objetivos del An√°lisis**
El an√°lisis de datos se basar√° en diferentes √°reas clave:
#### **An√°lisis de Ventas**
- Total de ventas por categor√≠a de producto (`sales.csv` + `categories.csv`).
- Descuentos aplicados y su impacto en las ventas (`sales.csv` ‚Üí `Discount`, `TotalPrice`).
- Productos m√°s vendidos y menos vendidos (`sales.csv` + `products.csv`).
####  **An√°lisis de Clientes**
- Distribuci√≥n geogr√°fica de clientes (`customers.csv` + `cities.csv` + `countries.csv`).
- Clientes con m√°s compras (`sales.csv` + `customers.csv`).
- Segmentaci√≥n de clientes (seg√∫n frecuencia de compra, monto total gastado).
####  **An√°lisis de Empleados y Ventas**
- Rendimiento de los empleados en ventas (`sales.csv` + `employees.csv`).
- Tiempo medio de contrataci√≥n de empleados (`employees.csv` ‚Üí `HireDate`).
####  **Otros An√°lisis Interesantes**
- Productos con mayor margen de ganancia (`products.csv` + `sales.csv`).
- Ciudades y pa√≠ses con mayor volumen de ventas (`sales.csv` + `cities.csv` + `countries.csv`).

## üìÇ **Estructura del Proyecto**
El proyecto sigue la siguiente organizaci√≥n de carpetas y archivos:
 **data/** ‚Üí Carpeta principal de los datos  
 **data_raw/** ‚Üí Archivos CSV sin procesar  
`categories.csv` ‚Üí Contiene las categor√≠as de productos (`CategoryID`, `CategoryName`).  
 `cities.csv` ‚Üí Informaci√≥n de ciudades (`CityID`, `CityName`, `Zipcode`, `CountryID`).  
 `countries.csv` ‚Üí Informaci√≥n de pa√≠ses (`CountryID`, `CountryName`, `CountryCode`).  
 `customers.csv` ‚Üí Datos de clientes (`CustomerID`, `FirstName`, `LastName`, `CityID`, `Address`).  
 `products.csv` ‚Üí Detalles de productos (`ProductID`, `ProductName`, `Price`, `CategoryID`, `Class`, `ModifyDate`).  
 `sales.csv` ‚Üí Datos transaccionales de ventas (`SalesID`, `SalesPersonID`, `CustomerID`, `ProductID`, `Quantity`, `Discount`, `TotalPrice`, `SalesDate`, `TransactionNumber`). 
**data_limpios/** ‚Üí Archivos procesados listos para Power BI  
**src/** ‚Üí C√≥digo fuente en Python para limpieza y transformaci√≥n  
**jupyters/** ‚Üí Notebooks para an√°lisis exploratorio  
**documentaci√≥n/** ‚Üí Archivo de trabajo  
`.gitignore` ‚Üí Archivos que no se deben subir al repositorio  
`README.md` ‚Üí Documento con la descripci√≥n del proyecto  
`requirements.txt` ‚Üí Lista de librer√≠as necesarias  

## Segunda Sesion
### ETL - Preeliminar

En esta segunda sesi√≥n, se proceder√° a la lectura y exploraci√≥n de los archivos **uno por uno** con el objetivo de:
- Obtener una visi√≥n general de la estructura y contenido de cada dataset.
- Identificar posibles transformaciones necesarias para la limpieza y normalizaci√≥n de datos.
- Evaluar la calidad de los datos, incluyendo tipos de variables, valores nulos y posibles inconsistencias.

### üöÄ **Exploraci√≥n Inicial del Dataset `categories.csv`**
Se ha realizado una primera exploraci√≥n del archivo `categories.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
 **Informaci√≥n general:**
- **N√∫mero de columnas:** 2 (`CategoryID`, `CategoryName`).
- **N√∫mero de filas:** 11.
- **Tipos de datos:**
  - `CategoryID` ‚Üí `int64` (identificador num√©rico de categor√≠a).
  - `CategoryName` ‚Üí `object` (nombre de la categor√≠a en texto).
- **Valores nulos:** No se han encontrado valores nulos en ninguna columna.
‚úÖ **Conclusi√≥n:**  
El dataset est√° limpio y no requiere tratamiento de valores nulos. Solo se aplicar√°n **transformaciones en los nombres de las columnas** para mejorar la legibilidad y estandarizaci√≥n.


### üöÄ **Exploraci√≥n Inicial del Dataset `cities.csv`**
Se ha realizado una primera exploraci√≥n del archivo `cities.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**Informaci√≥n general:**  
- **N√∫mero de columnas:** 4 (`CityID`, `CityName`, `Zipcode`, `CountryID`).  
- **N√∫mero de filas:** 96.  
- **Tipos de datos:**  
  - `CityID` ‚Üí `int64` (identificador √∫nico de la ciudad).  
  - `CityName` ‚Üí `object` (nombre de la ciudad).  
  - `Zipcode` ‚Üí `int64` (c√≥digo postal de la ciudad).  
  - `CountryID` ‚Üí `int64` (identificador del pa√≠s al que pertenece la ciudad).  
- **Valores nulos:** No se han encontrado valores nulos.  
‚úÖ **Conclusi√≥n:**  
El dataset est√° **completo y sin valores nulos**, pero se aplicar√°n algunas **transformaciones de limpieza**


### üöÄ **Exploraci√≥n Inicial del Dataset `countries.csv`**
Se ha realizado una primera exploraci√≥n del archivo `countries.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**Informaci√≥n general:**  
- **N√∫mero de columnas:** 3 (`CountryID`, `CountryName`, `CountryCode`).  
- **N√∫mero de filas:** 206.  
- **Tipos de datos:**  
  - `CountryID` ‚Üí `int64` (identificador √∫nico del pa√≠s).  
  - `CountryName` ‚Üí `object` (nombre del pa√≠s).  
  - `CountryCode` ‚Üí `object` (c√≥digo de pa√≠s de dos o tres letras, seg√∫n est√°ndar ISO).  
- **Valores nulos:**  **Se encontr√≥ 1 valor nulo en `CountryCode`**, mientras que las dem√°s columnas est√°n completas.  
‚úÖ **Conclusi√≥n y Acciones de Limpieza:**  El dataset **est√° casi completo**, pero se realizar√°n algunas **transformaciones** para mejorar su estructura. 


### üöÄ **Exploraci√≥n Inicial del Dataset `customers.csv`**
Se ha realizado una primera exploraci√≥n del archivo `customers.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
 **Informaci√≥n general:**  
- **N√∫mero de columnas:** 6 (`CustomerID`, `FirstName`, `MiddleInitial`, `LastName`, `CityID`, `Address`).  
- **N√∫mero de filas:** 98,759.  
- **Tipos de datos:**  
  - `CustomerID` ‚Üí `int64` (identificador √∫nico del cliente).  
  - `FirstName` ‚Üí `object` (nombre del cliente).  
  - `MiddleInitial` ‚Üí `object` (inicial del segundo nombre, puede estar ausente en algunos casos).  
  - `LastName` ‚Üí `object` (apellido del cliente).  
  - `CityID` ‚Üí `int64` (identificador de la ciudad de residencia).  
  - `Address` ‚Üí `object` (direcci√≥n completa del cliente).  
- **Valores nulos:**  **`MiddleInitial` tiene 977 nulos** (`97782` valores no nulos de `98759`).  Las dem√°s columnas est√°n completas.  
‚úÖ **Conclusi√≥n y Acciones de Limpieza:**  El dataset **est√° casi completo**, pero se realizar√°n algunas **transformaciones** para mejorar su estructura:  


# üöÄ **Exploraci√≥n Inicial del Dataset `employees.csv`**
Se ha realizado una primera exploraci√≥n del archivo `employees.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**Informaci√≥n general:**  
- **N√∫mero de columnas:** 8 (`EmployeeID`, `FirstName`, `MiddleInitial`, `LastName`, `BirthDate`, `Gender`, `CityID`, `HireDate`).  
- **N√∫mero de filas:** 23.  
- **Tipos de datos:**  
  - `EmployeeID` ‚Üí `int64` (identificador √∫nico del empleado).  
  - `FirstName` ‚Üí `object` (nombre del empleado).  
  - `MiddleInitial` ‚Üí `object` (inicial del segundo nombre del empleado).  
  - `LastName` ‚Üí `object` (apellido del empleado).  
  - `BirthDate` ‚Üí `object` (fecha de nacimiento, almacenada como string con formato `YYYY-MM-DD HH:MM:SS.sss`).  
  - `Gender` ‚Üí `object` (g√©nero del empleado).  
  - `CityID` ‚Üí `int64` (identificador de la ciudad donde reside el empleado).  
  - `HireDate` ‚Üí `object` (fecha de contrataci√≥n, almacenada como string con formato `YYYY-MM-DD HH:MM:SS.sss`).  
- **Valores nulos:**  No se han encontrado valores nulos en ninguna columna.  
‚úÖ **Conclusi√≥n y Acciones de Limpieza:**  El dataset **est√° completo y sin valores nulos**, pero se realizar√°n algunas **transformaciones** para mejorar su estructura y facilitar su an√°lisis:  

# üöÄ **Exploraci√≥n Inicial del Dataset `products.csv`**
Se ha realizado una primera exploraci√≥n del archivo `products.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**Informaci√≥n general:**  
- **N√∫mero de columnas:** 9 (`ProductID`, `ProductName`, `Price`, `CategoryID`, `Class`, `ModifyDate`, `Resistant`, `IsAllergic`, `VitalityDays`).  
- **N√∫mero de filas:** 452.  
- **Tipos de datos:**  
  - `ProductID` ‚Üí `int64` (identificador √∫nico del producto).  
  - `ProductName` ‚Üí `object` (nombre del producto).  
  - `Price` ‚Üí `float64` (precio del producto).  
  - `CategoryID` ‚Üí `int64` (identificador de la categor√≠a del producto).  
  - `Class` ‚Üí `object` (clasificaci√≥n del producto).  
  - `ModifyDate` ‚Üí `object` (fecha de √∫ltima modificaci√≥n, requiere conversi√≥n a formato `datetime`).  
  - `Resistant` ‚Üí `object` (nivel de resistencia del producto, valores incluyen `Durable`, `Weak`, `Unknown`).  
  - `IsAllergic` ‚Üí `object` (indica si el producto es alerg√©nico, valores incluyen `True`, `False`, `Unknown`).  
  - `VitalityDays` ‚Üí `float64` (n√∫mero de d√≠as que el producto mantiene su vitalidad o frescura, aunque deber√≠a ser un n√∫mero entero).  
- **Valores nulos:** No se han encontrado valores nulos, pero las columnas `Resistant` e `IsAllergic` contienen valores `"Unknown"` que podr√≠an requerir tratamiento.  
‚úÖ **Conclusi√≥n y Acciones de Limpieza:**  El dataset **est√° completo**, pero se realizar√°n algunas **transformaciones** para mejorar su estructura:  

# üöÄ **Exploraci√≥n Inicial del Dataset `sales.csv`**
Se ha realizado una primera exploraci√≥n del archivo `sales.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**Informaci√≥n general:**  
- **N√∫mero de columnas:** 9 (`SalesID`, `SalesPersonID`, `CustomerID`, `ProductID`, `Quantity`, `Discount`, `TotalPrice`, `SalesDate`, `TransactionNumber`).  
- **N√∫mero de filas:** 6,758,125.  
- **Tipos de datos:**  
  - `SalesID` ‚Üí `int64` (identificador √∫nico de la venta).  
  - `SalesPersonID` ‚Üí `int64` (identificador del vendedor).  
  - `CustomerID` ‚Üí `int64` (identificador del cliente).  
  - `ProductID` ‚Üí `int64` (identificador del producto vendido).  
  - `Quantity` ‚Üí `int64` (cantidad de productos vendidos).  
  - `Discount` ‚Üí `float64` (descuento aplicado en la venta).  
  - `TotalPrice` ‚Üí `float64` (precio total de la venta despu√©s del descuento).  
  - `SalesDate` ‚Üí `object` (fecha de la venta, requiere conversi√≥n a formato `datetime`).  
  - `TransactionNumber` ‚Üí `object` (c√≥digo √∫nico de transacci√≥n, se evaluar√° si es realmente necesario).  
- **Valores nulos:**  **`SalesDate` tiene valores nulos**, lo que requiere tratamiento.  El resto de las columnas est√°n completas.  
‚úÖ **Conclusi√≥n y Acciones de Limpieza:**  El dataset **es extenso y mayormente completo**, pero se realizar√°n algunas **transformaciones** para mejorar su estructura y optimizar su an√°lisis.

## Tercera Sesi√≥n
### Limpieza y transformaci√≥n  

En esta tercera sesi√≥n, se proceder√° a la limpieza y transformaci√≥n de los archivos **uno por uno**.  

#### categories.csv:  
- Se limpiaron los nombres de columnas ‚Üí `Category_Id`, `Category_Name`.  
- Se verificaron valores √∫nicos.  
- Se gener√≥ `describe().T` para analizar datos num√©ricos.  
- Se guard√≥ el dataset limpio en `data_limpios/`.  

#### cities.csv:  
- Se limpiaron los nombres de columnas ‚Üí `City_Id`, `City_Name`, `Zipcode`.  
- Se verificaron valores √∫nicos y duplicados en `City_Id` y `City_Name`.  
- Se elimin√≥ la columna `CountryID` (ten√≠a siempre el mismo valor).  
- Se convirti√≥ `Zipcode` a `str` (c√≥digo postal como identificador).  
- Se guard√≥ el dataset limpio en `data_limpios/`.  

#### countries.csv:
- Se limpiaron los nombres de columnas ‚Üí Country_Id, Country_Name, Country_Code
- Se verificaron duplicados en CountryID, CountryName y CountryCode
- Se normalizaron los nombres de los pa√≠ses (eliminando espacios y pasando a min√∫sculas)
- Se identific√≥ un valor nulo en CountryCode para Australia, pero no se modific√≥ por el momento
- Se guard√≥ el dataset limpio en data_limpios/

#### customers.csv:
- Se elimin√≥ la columna MiddleInitial porque no aportaba valor
- Se limpiaron los nombres de columnas ‚Üí Customer_Id, First_Name, Last_Name, City_Id, Address
- Se concatenaron las columnas First_Name y Last_Name en Full_Name y se elimin√≥ First_Name y Last_Name
- Se guard√≥ el dataset limpio en data_limpios/


#### Script de limpieza:
Se cre√≥ el script sp_limpieza.py en la carpeta src, con las siguientes funciones:
- Limpiar_nombres_columnas(df): Normaliza los nombres de las columnas eliminando espacios, caracteres especiales y aplicando formato estandarizado.
- Valores_unicos(df): Muestra los valores √∫nicos de cada columna del DataFrame.
- Concatenar_nombres(df): Concatena First_Name y Last_Name en Full_Name, posicion√°ndola despu√©s de Customer_Id y eliminando las columnas originales.



## **Tareas Pendientes**
Completar el proceso de **ETL** utilizando **Python**.
Crear un **modelo estrella** en **Power BI** para facilitar el an√°lisis.
Implementar y validar el **flujo de trabajo de visualizaci√≥n de datos** en **Power BI**.

---

**Este proyecto est√° en curso**, y se espera que las pr√≥ximas fases se centren en la implementaci√≥n de la **ETL** y en el **an√°lisis con Power BI**. üöÄüìä

