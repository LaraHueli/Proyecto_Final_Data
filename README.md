# Protecto_Final_Data - AnÃ¡lisis de Datos

## Primera SesiÃ³n
### DescripciÃ³n del Proyecto
Este es un proyecto final donde se trabajarÃ¡ en la transformaciÃ³n, limpieza y anÃ¡lisis de datos. Mi enfoque es hacer una **ETL** (extracciÃ³n, transformaciÃ³n y carga) utilizando **Python** para la limpieza y transformaciÃ³n de los datos, y luego realizar el anÃ¡lisis y la visualizaciÃ³n utilizando **Power BI**.

#### Nota de la conversaciÃ³n con Silvia
Una vez hablado con Silvia, mi intenciÃ³n es hacer una ETL en Python y utilizar Power BI para el anÃ¡lisis y la visualizaciÃ³n. He recibido su aprobaciÃ³n para esta estrategia, siempre y cuando utilice Python para la limpieza y transformaciÃ³n de los datos. 
Le he explicado que tengo 7 bases de datos diferentes y que mi objetivo es pasar de un modelo en copo de nieve a un modelo estrella en Power BI y asi poder usar la herramienta en la que me estoy especializando al maximo, sin olvidar el resto.

## Objetivos
### **Objetivos del AnÃ¡lisis**
El anÃ¡lisis de datos se basarÃ¡ en diferentes Ã¡reas clave:
#### **AnÃ¡lisis de Ventas**
- Total de ventas por categorÃ­a de producto (`sales.csv` + `categories.csv`).
- Descuentos aplicados y su impacto en las ventas (`sales.csv` â†’ `Discount`, `TotalPrice`).
- Productos mÃ¡s vendidos y menos vendidos (`sales.csv` + `products.csv`).
####  **AnÃ¡lisis de Clientes**
- DistribuciÃ³n geogrÃ¡fica de clientes (`customers.csv` + `cities.csv` + `countries.csv`).
- Clientes con mÃ¡s compras (`sales.csv` + `customers.csv`).
- SegmentaciÃ³n de clientes (segÃºn frecuencia de compra, monto total gastado).
####  **AnÃ¡lisis de Empleados y Ventas**
- Rendimiento de los empleados en ventas (`sales.csv` + `employees.csv`).
- Tiempo medio de contrataciÃ³n de empleados (`employees.csv` â†’ `HireDate`).
####  **Otros AnÃ¡lisis Interesantes**
- Productos con mayor margen de ganancia (`products.csv` + `sales.csv`).
- Ciudades y paÃ­ses con mayor volumen de ventas (`sales.csv` + `cities.csv` + `countries.csv`).

## ğŸ“‚ **Estructura del Proyecto**
El proyecto sigue la siguiente organizaciÃ³n de carpetas y archivos:
 **data/** â†’ Carpeta principal de los datos  
 **data_raw/** â†’ Archivos CSV sin procesar  
`categories.csv` â†’ Contiene las categorÃ­as de productos (`CategoryID`, `CategoryName`).  
 `cities.csv` â†’ InformaciÃ³n de ciudades (`CityID`, `CityName`, `Zipcode`, `CountryID`).  
 `countries.csv` â†’ InformaciÃ³n de paÃ­ses (`CountryID`, `CountryName`, `CountryCode`).  
 `customers.csv` â†’ Datos de clientes (`CustomerID`, `FirstName`, `LastName`, `CityID`, `Address`).  
 `products.csv` â†’ Detalles de productos (`ProductID`, `ProductName`, `Price`, `CategoryID`, `Class`, `ModifyDate`).  
 `sales.csv` â†’ Datos transaccionales de ventas (`SalesID`, `SalesPersonID`, `CustomerID`, `ProductID`, `Quantity`, `Discount`, `TotalPrice`, `SalesDate`, `TransactionNumber`). 
**data_limpios/** â†’ Archivos procesados listos para Power BI  
**src/** â†’ CÃ³digo fuente en Python para limpieza y transformaciÃ³n  
**jupyters/** â†’ Notebooks para anÃ¡lisis exploratorio  
**documentaciÃ³n/** â†’ Archivo de trabajo  
`.gitignore` â†’ Archivos que no se deben subir al repositorio  
`README.md` â†’ Documento con la descripciÃ³n del proyecto  
`requirements.txt` â†’ Lista de librerÃ­as necesarias  

## Segunda SesiÃ³n
### ETL - Preeliminar

En esta segunda sesiÃ³n, se procederÃ¡ a la lectura y exploraciÃ³n de los archivos **uno por uno** con el objetivo de:
- Obtener una visiÃ³n general de la estructura y contenido de cada dataset.
- Identificar posibles transformaciones necesarias para la limpieza y normalizaciÃ³n de datos.
- Evaluar la calidad de los datos, incluyendo tipos de variables, valores nulos y posibles inconsistencias.

###  **ExploraciÃ³n Inicial del Dataset `categories.csv`**
Se ha realizado una primera exploraciÃ³n del archivo `categories.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
 **InformaciÃ³n general:**
- **NÃºmero de columnas:** 2 (`CategoryID`, `CategoryName`).
- **NÃºmero de filas:** 11.
- **Tipos de datos:**
  - `CategoryID` â†’ `int64` (identificador numÃ©rico de categorÃ­a).
  - `CategoryName` â†’ `object` (nombre de la categorÃ­a en texto).
- **Valores nulos:** No se han encontrado valores nulos en ninguna columna.
âœ… **ConclusiÃ³n:**  
El dataset estÃ¡ limpio y no requiere tratamiento de valores nulos. Solo se aplicarÃ¡n **transformaciones en los nombres de las columnas** para mejorar la legibilidad y estandarizaciÃ³n.


### **ExploraciÃ³n Inicial del Dataset `cities.csv`**
Se ha realizado una primera exploraciÃ³n del archivo `cities.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**InformaciÃ³n general:**  
- **NÃºmero de columnas:** 4 (`CityID`, `CityName`, `Zipcode`, `CountryID`).  
- **NÃºmero de filas:** 96.  
- **Tipos de datos:**  
  - `CityID` â†’ `int64` (identificador Ãºnico de la ciudad).  
  - `CityName` â†’ `object` (nombre de la ciudad).  
  - `Zipcode` â†’ `int64` (cÃ³digo postal de la ciudad).  
  - `CountryID` â†’ `int64` (identificador del paÃ­s al que pertenece la ciudad).  
- **Valores nulos:** No se han encontrado valores nulos.  
âœ… **ConclusiÃ³n:**  
El dataset estÃ¡ **completo y sin valores nulos**, pero se aplicarÃ¡n algunas **transformaciones de limpieza**


### **ExploraciÃ³n Inicial del Dataset `countries.csv`**
Se ha realizado una primera exploraciÃ³n del archivo `countries.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**InformaciÃ³n general:**  
- **NÃºmero de columnas:** 3 (`CountryID`, `CountryName`, `CountryCode`).  
- **NÃºmero de filas:** 206.  
- **Tipos de datos:**  
  - `CountryID` â†’ `int64` (identificador Ãºnico del paÃ­s).  
  - `CountryName` â†’ `object` (nombre del paÃ­s).  
  - `CountryCode` â†’ `object` (cÃ³digo de paÃ­s de dos o tres letras, segÃºn estÃ¡ndar ISO).  
- **Valores nulos:**  **Se encontrÃ³ 1 valor nulo en `CountryCode`**, mientras que las demÃ¡s columnas estÃ¡n completas.  
âœ… **ConclusiÃ³n y Acciones de Limpieza:**  El dataset **estÃ¡ casi completo**, pero se realizarÃ¡n algunas **transformaciones** para mejorar su estructura. 


### **ExploraciÃ³n Inicial del Dataset `customers.csv`**
Se ha realizado una primera exploraciÃ³n del archivo `customers.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
 **InformaciÃ³n general:**  
- **NÃºmero de columnas:** 6 (`CustomerID`, `FirstName`, `MiddleInitial`, `LastName`, `CityID`, `Address`).  
- **NÃºmero de filas:** 98,759.  
- **Tipos de datos:**  
  - `CustomerID` â†’ `int64` (identificador Ãºnico del cliente).  
  - `FirstName` â†’ `object` (nombre del cliente).  
  - `MiddleInitial` â†’ `object` (inicial del segundo nombre, puede estar ausente en algunos casos).  
  - `LastName` â†’ `object` (apellido del cliente).  
  - `CityID` â†’ `int64` (identificador de la ciudad de residencia).  
  - `Address` â†’ `object` (direcciÃ³n completa del cliente).  
- **Valores nulos:**  **`MiddleInitial` tiene 977 nulos** (`97782` valores no nulos de `98759`).  Las demÃ¡s columnas estÃ¡n completas.  
âœ… **ConclusiÃ³n y Acciones de Limpieza:**  El dataset **estÃ¡ casi completo**, pero se realizarÃ¡n algunas **transformaciones** para mejorar su estructura:  


###  **ExploraciÃ³n Inicial del Dataset `employees.csv`**
Se ha realizado una primera exploraciÃ³n del archivo `employees.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**InformaciÃ³n general:**  
- **NÃºmero de columnas:** 8 (`EmployeeID`, `FirstName`, `MiddleInitial`, `LastName`, `BirthDate`, `Gender`, `CityID`, `HireDate`).  
- **NÃºmero de filas:** 23.  
- **Tipos de datos:**  
  - `EmployeeID` â†’ `int64` (identificador Ãºnico del empleado).  
  - `FirstName` â†’ `object` (nombre del empleado).  
  - `MiddleInitial` â†’ `object` (inicial del segundo nombre del empleado).  
  - `LastName` â†’ `object` (apellido del empleado).  
  - `BirthDate` â†’ `object` (fecha de nacimiento, almacenada como string con formato `YYYY-MM-DD HH:MM:SS.sss`).  
  - `Gender` â†’ `object` (gÃ©nero del empleado).  
  - `CityID` â†’ `int64` (identificador de la ciudad donde reside el empleado).  
  - `HireDate` â†’ `object` (fecha de contrataciÃ³n, almacenada como string con formato `YYYY-MM-DD HH:MM:SS.sss`).  
- **Valores nulos:**  No se han encontrado valores nulos en ninguna columna.  
âœ… **ConclusiÃ³n y Acciones de Limpieza:**  El dataset **estÃ¡ completo y sin valores nulos**, pero se realizarÃ¡n algunas **transformaciones** para mejorar su estructura y facilitar su anÃ¡lisis:  

### **ExploraciÃ³n Inicial del Dataset `products.csv`**
Se ha realizado una primera exploraciÃ³n del archivo `products.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**InformaciÃ³n general:**  
- **NÃºmero de columnas:** 9 (`ProductID`, `ProductName`, `Price`, `CategoryID`, `Class`, `ModifyDate`, `Resistant`, `IsAllergic`, `VitalityDays`).  
- **NÃºmero de filas:** 452.  
- **Tipos de datos:**  
  - `ProductID` â†’ `int64` (identificador Ãºnico del producto).  
  - `ProductName` â†’ `object` (nombre del producto).  
  - `Price` â†’ `float64` (precio del producto).  
  - `CategoryID` â†’ `int64` (identificador de la categorÃ­a del producto).  
  - `Class` â†’ `object` (clasificaciÃ³n del producto).  
  - `ModifyDate` â†’ `object` (fecha de Ãºltima modificaciÃ³n, requiere conversiÃ³n a formato `datetime`).  
  - `Resistant` â†’ `object` (nivel de resistencia del producto, valores incluyen `Durable`, `Weak`, `Unknown`).  
  - `IsAllergic` â†’ `object` (indica si el producto es alergÃ©nico, valores incluyen `True`, `False`, `Unknown`).  
  - `VitalityDays` â†’ `float64` (nÃºmero de dÃ­as que el producto mantiene su vitalidad o frescura, aunque deberÃ­a ser un nÃºmero entero).  
- **Valores nulos:** No se han encontrado valores nulos, pero las columnas `Resistant` e `IsAllergic` contienen valores `"Unknown"` que podrÃ­an requerir tratamiento.  
âœ… **ConclusiÃ³n y Acciones de Limpieza:**  El dataset **estÃ¡ completo**, pero se realizarÃ¡n algunas **transformaciones** para mejorar su estructura:  

### **ExploraciÃ³n Inicial del Dataset `sales.csv`**
Se ha realizado una primera exploraciÃ³n del archivo `sales.csv` para entender su estructura y verificar la necesidad de limpieza o transformaciones.
**InformaciÃ³n general:**  
- **NÃºmero de columnas:** 9 (`SalesID`, `SalesPersonID`, `CustomerID`, `ProductID`, `Quantity`, `Discount`, `TotalPrice`, `SalesDate`, `TransactionNumber`).  
- **NÃºmero de filas:** 6,758,125.  
- **Tipos de datos:**  
  - `SalesID` â†’ `int64` (identificador Ãºnico de la venta).  
  - `SalesPersonID` â†’ `int64` (identificador del vendedor).  
  - `CustomerID` â†’ `int64` (identificador del cliente).  
  - `ProductID` â†’ `int64` (identificador del producto vendido).  
  - `Quantity` â†’ `int64` (cantidad de productos vendidos).  
  - `Discount` â†’ `float64` (descuento aplicado en la venta).  
  - `TotalPrice` â†’ `float64` (precio total de la venta despuÃ©s del descuento).  
  - `SalesDate` â†’ `object` (fecha de la venta, requiere conversiÃ³n a formato `datetime`).  
  - `TransactionNumber` â†’ `object` (cÃ³digo Ãºnico de transacciÃ³n, se evaluarÃ¡ si es realmente necesario).  
- **Valores nulos:**  **`SalesDate` tiene valores nulos**, lo que requiere tratamiento.  El resto de las columnas estÃ¡n completas.  
âœ… **ConclusiÃ³n y Acciones de Limpieza:**  El dataset **es extenso y mayormente completo**, pero se realizarÃ¡n algunas **transformaciones** para mejorar su estructura y optimizar su anÃ¡lisis.

## Tercera SesiÃ³n
### Limpieza y transformaciÃ³n  

En esta tercera sesiÃ³n, se procederÃ¡ a la limpieza y transformaciÃ³n de los archivos **uno por uno**.  

#### categories.csv:  
- Se limpiaron los nombres de columnas â†’ `Category_Id`, `Category_Name`.  
- Se verificaron valores Ãºnicos.  
- Se generÃ³ `describe().T` para analizar datos numÃ©ricos.  
- Se guardÃ³ el dataset limpio en `data_limpios/`.  

#### cities.csv:  
- Se limpiaron los nombres de columnas â†’ `City_Id`, `City_Name`, `Zipcode`.  
- Se verificaron valores Ãºnicos y duplicados en `City_Id` y `City_Name`.  
- Se eliminÃ³ la columna `CountryID` (tenÃ­a siempre el mismo valor).  
- Se convirtiÃ³ `Zipcode` a `str` (cÃ³digo postal como identificador).  
- Se guardÃ³ el dataset limpio en `data_limpios/`.  

#### countries.csv:
- Se limpiaron los nombres de columnas â†’ `Country_Id`, `Country_Name`, `Country_Code`.
- Se verificaron duplicados en `Country_Id`, `Country_Name` y `Country_Code`.
- Se normalizaron los nombres de los paÃ­ses (eliminando espacios y pasando a minÃºsculas).
- Se identificÃ³ un valor nulo en `Country_Code` para Australia, pero no se modificÃ³ por el momento.
- Se guardÃ³ el dataset limpio en `data_limpios/`.

#### customers.csv:
- Se eliminÃ³ la columna `MiddleInitial` porque no aportaba valor.
- Se limpiaron los nombres de columnas â†’ `Customer_Id`, `First_Name`, `Last_Name`, `City_Id`, `Address`.
- Se concatenaron las columnas `First_Name` y `Last_Name` en `Full_Name`, eliminando las originales.
- Se guardÃ³ el dataset limpio en `data_limpios/`.


#### employees.csv:
- Se eliminÃ³ la columna `MiddleInitial` porque no aportaba valor.
- Se limpiaron los nombres de columnas â†’ `Employee_Id`, `Full_Name`, `Birth_Date`, `Gender`, `City_Id`, `Hire_Date`.
- Se concatenaron las columnas `First_Name` y `Last_Name` en `Full_Name`, eliminando las originales.
- Se convirtieron las fechas `BirthDate` y `HireDate` a formato `YYYY-MM-DD`.
- Se calculÃ³ la edad (`Age`) a partir de `BirthDate`.
- Se calculÃ³ la antigÃ¼edad (`YearsInCompany`) a partir de `HireDate`.
- Se guardÃ³ el dataset limpio en `data_limpios/`.
**AnÃ¡lisis de `describe()`**
- **Edad (`Age`)**:Rango de edad: 36 a 74 aÃ±os. Promedio: 57 aÃ±os. El 50% de los empleados tienen entre 51 y 63 aÃ±os.
- **AÃ±os en la empresa (`YearsInCompany`)**: Rango: 8 a 15 aÃ±os. Promedio: 11.8 aÃ±os. El 50% de los empleados tienen entre 10.5 y 14 aÃ±os en la empresa.
**Conclusiones:**
- La empresa tiene una plantilla mayormente **senior**, con edades promedio de 57 aÃ±os.
- La mayorÃ­a de los empleados tienen mÃ¡s de 10 aÃ±os de antigÃ¼edad, lo que sugiere una buena retenciÃ³n laboral.
- Se recomienda analizar la distribuciÃ³n de edades en Power BI para evaluar la planificaciÃ³n de talento y sucesiÃ³n.

#### products.csv:
- Se limpiaron los nombres de columnas con `limpiar_nombres_columnas()`, manteniendo el contenido original.  
- Se convirtiÃ³ la columna `Modify_Date` a formato `YYYY-MM-DD`.  
- Se reemplazÃ³ `"Unknown"` por `"Unspecified"` en `Resistant` e `Is_Allergic` para facilitar el anÃ¡lisis en Power BI.  
- Se convirtiÃ³ `Vitality_Days` de `float` a `int`.  
- Se analizaron los valores con `describe()` y se identificaron posibles valores extremos en `Price` y `Vitality_Days`.  
- Se generaron grÃ¡ficos (histograma y boxplot) para evaluar su distribuciÃ³n y detectar outliers.  
- Se analizaron los productos con `Vitality_Days = 0`, identificando sus categorÃ­as y clases. 
- Se guardÃ³ el dataset limpio en `data_limpios/`. 
**AnÃ¡lisis de `describe()`**  
- **Price**: Rango de valores entre 0.0449 y 99.87. DistribuciÃ³n normal sin valores extremos preocupantes.  
- **Vitality_Days**: Rango de 0 a 120 dÃ­as. Se detectaron valores en 0, analizados por categorÃ­a y clase.  
**Conclusiones:**  
- La mayorÃ­a de los productos con `Vitality_Days = 0` pertenecen a clases `Medium` y `High`, con categorÃ­as diversas.  
- No se detectaron valores atÃ­picos en `Price`, por lo que no se realizaron modificaciones.  
- Se recomienda analizar en Power BI la distribuciÃ³n de `Vitality_Days` y su relaciÃ³n con las categorÃ­as de productos.  

#### **sales.csv:**
- Se verificaron los valores nulos en la columna `SalesDate` y se decidiÃ³ eliminar los valores nulos (1%) para mantener la consistencia de los datos.
- Se limpiaron los nombres de columnas con `limpiar_nombres_columnas()`, estandarizando los nombres de las columnas.
- Se separaron las fechas en dos nuevas columnas: `Day_Sales` (con solo la fecha) y `Hour_Sales` (con solo la hora) para facilitar su anÃ¡lisis en Power BI.
- Se determinÃ³ que las columnas `SalesID` y `Transaction_Number` eran redundantes, por lo que se eliminÃ³ `Transaction_Number`.
- Se analizÃ³ el dataset con `describe()` y se encontraron valores tÃ­picos en las columnas como `Quantity` y `SalesID`.
- Se guardÃ³ el dataset limpio en `data_limpios/`.
**AnÃ¡lisis de `describe()`**
- **SalesID**: Rango de valores entre 1 y 6758125.
- **TotalPrice**: Todos los valores son 0, no se realizaron modificaciones.
- **Quantity**: Valores tÃ­picos de productos vendidos entre 7 y 25.
**Conclusiones:**
- Se eliminaron los valores nulos de `SalesDate` para asegurar la consistencia del dataset.
- Los nombres de las columnas fueron estandarizados.
- La separaciÃ³n de las fechas en `Day_Sales` y `Hour_Sales` permite explorar mÃ¡s fÃ¡cilmente las tendencias de ventas por hora en Power BI.
- Se eliminÃ³ `Transaction_Number` ya que era redundante con `SalesID`.


#### Script de limpieza:
Se creÃ³ el script sp_limpieza.py en la carpeta src, con las siguientes funciones:
- Limpiar_nombres_columnas(df): Normaliza los nombres de las columnas eliminando espacios, caracteres especiales y aplicando formato estandarizado.
- Valores_unicos(df): Muestra los valores Ãºnicos de cada columna del DataFrame.
- Concatenar_nombres(df): Concatena First_Name y Last_Name en Full_Name, posicionÃ¡ndola despuÃ©s de Customer_Id y eliminando las columnas originales.
- limpiar_fechas(df): Para eliminar la horas de la fechas y dejar solo formato fecha
- calcular_edad (df): Partiendo de la fecha de nacimiento sacamos la edad actual
- aÃ±os_trabajados (df): partiendo de la fecha de contratacion sacamos los aÃ±os trabajados.
- convertir_a_entero (df): Convierte un numero float a int.
- separar_fecha_hora (df) : partiendo de la fecha de compra, sacamos dia y hora.


#### Script de visualizacion:
Se creÃ³ el script sp_visualizacion.py en la carpeta src, con las siguientes funciones:
- graficar_histograma (df): Genera un histograma para visualizar la distribuciÃ³n de una variable.
- graficar_boxplot(df): Genera un boxplot para identificar outliers.



## Cuarta SesiÃ³n
# Power BI  

Este documento detalla todos los pasos realizados en **Power BI** hasta el momento, desde la carga de datos hasta la optimizaciÃ³n del modelo y las tablas.  
## Fase 1: Carga de Datos  
### **ImportaciÃ³n de Datos**  
- Se importaron los archivos **limpios** desde la carpeta `data_limpios/` a Power BI.  
- Se verificÃ³ la estructura y calidad de los datos antes de proceder a modelarlos.  

## Fase 2: TransformaciÃ³n del Modelo de Datos  
### **ConversiÃ³n de Copo de Nieve a Modelo Estrella**  
- Se estableciÃ³ `sales_clean` como la **tabla de hechos** y el resto como **tablas de dimensiÃ³n**.  
- Se corrigieron y crearon **relaciones 1:* (uno a muchos)** para optimizar la estructura.  
- Se realizaron **agregaciones y combinaciones de consultas** en Power Query para mejorar el modelo.  
#### **AgrupaciÃ³n y CombinaciÃ³n de Consultas**  
- **`customers_clean`** se combinÃ³ con **`cities_clean`** a travÃ©s de `City_Id` para simplificar la estructura.  
- **`products_clean`** se combinÃ³ con **`categories_clean`** a travÃ©s de `Category_Id` para reducir el nÃºmero de tablas en el modelo.  
- **DeshabilitaciÃ³n de carga de `cities_clean` y `categories_clean`** para mejorar la eficiencia del modelo.  
- **CorrecciÃ³n en `cities_clean` en Python**, donde se restaurÃ³ una columna eliminada por error.  
- **RevisiÃ³n y ajuste de tipos de datos en todas las tablas** en Power Query.  

## Fase 3: Relaciones en Power BI  
### **Relaciones Establecidas en el Modelo Estrella**  
 **Tabla de Hechos (`sales_clean`)**  
- Se conecta con `products_clean` mediante **`Product_Id`**.  
- Se conecta con `employees_clean` mediante **`Employee_Id`** *(anteriormente `Sales_Person_Id`)*.  
- Se conecta con `customers_clean` mediante **`Customer_Id`**.  
 **Dimensiones con Relaciones Internas**  
- `customers_clean` incluye informaciÃ³n de `cities_clean` (ciudad y cÃ³digo postal).  
- `products_clean` incluye informaciÃ³n de `categories_clean` (nombre de categorÃ­a).  

## Fase 4: OptimizaciÃ³n y PreparaciÃ³n para VisualizaciÃ³n   
âœ… **Limpieza y OptimizaciÃ³n de `sales_clean`**  
- **`Discount`** convertido a decimal y multiplicado por 100 para representarlo como porcentaje.  
- **EliminaciÃ³n de columnas innecesarias:**  
  - âŒ `Hour_Full` (ya tenemos `Hour_Sales`).  
  - âŒ `Total_Price` (siempre estaba en 0).  
- **ReorganizaciÃ³n de columnas** para mejorar la interpretaciÃ³n de los datos.  

âœ… **Limpieza y OptimizaciÃ³n de `products_clean`**  
- **CorrecciÃ³n del formato de precios** â†’ Volvimos a **Python** para verificar y corregir valores.  
- **ConfirmaciÃ³n de que podemos calcular `Total_Ventas` en Power BI** con:  
  ```DAX
  Total_Ventas = SUMX(sales_clean, sales_clean[Quantity] * RELATED(products_clean[Price]))

âœ… **Limpieza y OptimizaciÃ³n de `employees_clean`**
- **ReorganizaciÃ³n de columnas** para mejorar la interpretaciÃ³n de los datos.   
**CorrecciÃ³n de Tipos de Datos**  
- `Employee_Id`, `City_Id`, `Years_Worked`, `Age` â†’ **NumÃ©rico (entero)**.  
- `Full_Name`, `Gender`, `Work_Category` â†’ **Texto**.  
- `Birth_Date`, `Hire_Date` â†’ **Fecha**.  
**Renombre de Columnas**: `Edad` â†’ **`Age`**. `AÃ±os Trabajados` â†’ **`Years_Worked`**. `CategorÃ­a Laboral` â†’ **`Work_Category`**.  
**Nueva Columna: `Work_Category`** : ClasificaciÃ³n de empleados segÃºn `Years_Worked`:  
- ğŸŸ¢ **Junior** â†’ â‰¤5 aÃ±os.  
- ğŸ”µ **Mid-Level** â†’ 6-10 aÃ±os.  
- ğŸ”´ **Senior** â†’ >10 aÃ±os.  
**MÃ©todo de CreaciÃ³n:**  
- Se utilizÃ³ una **columna condicional en Power Query** basada en `Years_Worked`.  

# âœ… Limpieza y OptimizaciÃ³n de `customers_clean`
- **UniÃ³n de `customers` con `cities` y `countries`** usando `City_Id` para traer el nombre de la ciudad y el paÃ­s.  
- **EliminaciÃ³n de columnas innecesarias:**  
  - âŒ `City_Id` (porque ya tenemos el nombre de la ciudad).  
  - âŒ `Country_Id` (porque ya tenemos el nombre del paÃ­s).  
- **ReorganizaciÃ³n de columnas** para mejorar la interpretaciÃ³n de los datos.  
---

ğŸ”§ CreaciÃ³n de Medidas en Power BI

Para realizar el anÃ¡lisis en Power BI, creamos las siguientes medidas en DAX:

âœ… Total Sales: Total Sales = SUM(sales[Total_Price_Calculated])âœ… Total Sales Volume: Total Sales Volume = SUM(sales[Quantity])âœ… Precio Promedio de Venta: Average Selling Price = AVERAGE(sales[Unit_Price])âœ… VariaciÃ³n de Precio de Venta: Price Variation = MAX(sales[Unit_Price]) - MIN(sales[Unit_Price])

âš ï¸ Se eliminÃ³ la mÃ©trica de Average Discount, ya que no aportaba valor al anÃ¡lisis.

ğŸ“Š CreaciÃ³n de la Primera Hoja de AnÃ¡lisis: Ventas y Rentabilidad

Se diseÃ±Ã³ una primera pÃ¡gina en Power BI enfocada en evaluar el volumen de ventas y la rentabilidad de los productos.

ğŸ“Œ AnÃ¡lisis realizado:

1ï¸âƒ£ Total de Productos Vendidos (87 millones) y Ventas Totales ($4.02 billones)

Se ha vendido un volumen alto de productos, lo que indica una alta demanda.

Falta contexto temporal para saber si las ventas estÃ¡n creciendo o son estables.

2ï¸âƒ£ VariaciÃ³n de Precio de Venta ($99.83 mil) y Precio Promedio de Venta ($46.3 mil)

Hay una gran diferencia entre el precio mÃ­nimo y mÃ¡ximo de los productos vendidos.

Esto sugiere la presencia de productos premium y econÃ³micos.

3ï¸âƒ£ Productos MÃ¡s Vendidos (Ranking por cantidad de unidades vendidas)

Los productos con mayor demanda son Longos - Chicken Wings y Yoghurt Tubes.

Tener alta demanda no significa que sean los mÃ¡s rentables.

4ï¸âƒ£ Productos con Mayor Ingreso (Ranking por ventas totales en dÃ³lares)

Apricots - Dried y Yoghurt Tubes generan los mayores ingresos.

Algunos productos con menos unidades vendidas tienen precios altos y generan mÃ¡s ingresos.

ğŸ“Œ Conclusiones iniciales:

ğŸ”¹ Es importante analizar la rentabilidad de los productos mÃ¡s vendidos, ya que vender mÃ¡s unidades no siempre genera mÃ¡s ingresos.ğŸ”¹ Los productos premium (precios altos) pueden representar una parte significativa del ingreso total.ğŸ”¹ Se podrÃ­a analizar si los productos mÃ¡s vendidos tienen mÃ¡rgenes de ganancia altos o ajustados.


## ğŸ”œ PrÃ³ximos Pasos  
- **CreaciÃ³n de mÃ©tricas DAX** para KPIs clave.  
- **DiseÃ±o de dashboards y visualizaciones**.  
- **OptimizaciÃ³n de medidas para rendimiento en Power BI**.  

---

**Este proyecto estÃ¡ en curso**, y se espera que las prÃ³ximas fases se centren en la implementaciÃ³n de la **ETL** y en el **anÃ¡lisis con Power BI**. ğŸš€ğŸ“Š

